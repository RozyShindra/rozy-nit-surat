<div class="container">
    <h2 class="section-title">Professional Experience</h2>
    <div class="experience-list">
         <div class="card experience-card">
            <div class="experience-logo-container">
                <img src="https://raw.githubusercontent.com/RozyShindra/rozy-nit-surat/refs/heads/main/assests/images/logos/cigna.jpg"
                    alt="CIGNA Logo" class="exp-logo">
                <div class="experience-text">
                    <h3>Machine Learning Engineer</h3>
                    <h4>Cigna Healthcare - Evernorth</h4>
                    <p class="location">Hyderabad, Telangana | Nov 2025 – Present</p>
                </div>
            </div>


            <p class="summary">
                At Cigna, I worked on designing and implementing graph-driven, 
                agentic AI solutions for healthcare applications, 
                with a strong focus on performance, reliability, and explainability. 
                My work involved building patient-centric knowledge graphs, 
                experimenting with advanced RAG variants (RAG, GraphRAG, Agentic RAG), 
                and integrating Agentic AI with Pydantic AI to enforce structured, 
                validated outputs suitable for regulated healthcare environments. 
                I contributed to the Precision Underwriting (PUWP) initiative by 
                deeply analyzing healthcare datasets, modeling clinically and underwriting-relevant 
                entities, and translating raw data into structured graph representations. 
                <strong>I built an enterprise-grade GraphRAG POC using LangGraph, Neo4j/GraphDB, vector databases, and Databricks, 
                achieving approximately 70% improvement in response quality and latency 
                over the existing approach.</strong> 
               
            </p>

            <!-- Achievements Summary -->
            <h3>Achievements</h3>
            <ul class="achievements">
                <li>This work demonstrated the practical value of combining knowledge graphs, 
                    autonomous agents, and schema-validated LLM pipelines to deliver faster, more accurate, 
                    and more explainable AI systems in healthcare.</li>
            </ul>

            
            <div class="tech-tags">
                <span class="tech-tag">GraphRAG</span>
                <span class="tech-tag">Agentic RAG</span>
                <span class="tech-tag">Agentic AI & Autonomous Agents</span>
                <span class="tech-tag">Multi-step Reasoning Pipelines</span>
                <span class="tech-tag">Prompt Engineering</span>
                <span class="tech-tag">LangChain</span>
                <span class="tech-tag">LangGraph</span>
                <span class="tech-tag">Pydantic AI</span>
                <span class="tech-tag">Graphiti</span>
                <span class="tech-tag">Databricks</span>
                <span class="tech-tag">Apache Spark</span>
                <span class="tech-tag">Knowledge Graph Design</span>
                <span class="tech-tag">Patient-Centric Knowledge Graphs</span>
                <span class="tech-tag">Graph Schema & Ontology</span>
                <span class="tech-tag">Semantic Relationship Modeling</span>
                <span class="tech-tag">Temporal & Multi-hop Graph Reasoning</span>
                <span class="tech-tag">Graph-based Context Extraction</span>
                <span class="tech-tag">Neo4j</span>
                <span class="tech-tag">GraphDB</span>
                <span class="tech-tag">Cypher Query Language</span>
                <span class="tech-tag">Graph Traversals & Pattern Matching</span>
                <span class="tech-tag">Vector Databases</span>
                <span class="tech-tag">Dense Embedding-based Retrieval</span>
                <span class="tech-tag">Hybrid Retrieval (Vector + Graph)</span>
                <span class="tech-tag">Context Ranking & Relevance Optimization</span>
                <span class="tech-tag">Healthcare Data Analysis</span>
                <span class="tech-tag">Clinical Data Modeling</span>
                <span class="tech-tag">Patient Journey Representation</span>
                <span class="tech-tag">Precision Underwriting (PUWP)</span>
                
                
                <span class="tech-tag">Large-scale Data Processing</span>
                <span class="tech-tag">Data Profiling & Quality Analysis</span>
                <span class="tech-tag">Entity & Feature Extraction</span>
                <span class="tech-tag">End-to-End AI Architecture</span>
                <span class="tech-tag">Enterprise-grade POC Development</span>
                <span class="tech-tag">Scalable AI Pipelines</span>
                
                <span class="tech-tag">Modular & Agent-based System Design</span>
                
                <span class="tech-tag">Strongly Typed AI Pipelines</span>
                <span class="tech-tag">RAG Performance Benchmarking</span>
                <span class="tech-tag">Response Quality Evaluation</span>
                <span class="tech-tag">Latency Optimization</span>
                <span class="tech-tag">Comparative Architecture Analysis</span>
            </div>

            <!-- Research & Experimentation -->
            <h3>Research & Experiment</h3>
            <ul class="detailed-work">
                <li class="phase">
                    <h3 class="phase-title">Enterprise-Grade GraphRAG POC with Agentic AI and Pydantic AI</h3>
                    <p class="phase-desc">
                        Designed and implemented a high-performance, enterprise-ready Proof of Concept (POC) focused on transforming healthcare AI response quality and latency. The architecture combined <strong>vector-based semantic retrieval with structured traversal of healthcare knowledge graphs</strong>. Implemented <strong>Agentic AI workflows</strong> to decompose complex user queries, select optimal retrieval strategies dynamically, and orchestrate multi-step reasoning pipelines. Integrated <strong>Pydantic AI</strong> to enforce strongly typed agent inputs/outputs, validate structured responses against predefined schemas, and reduce LLM hallucinations. Used <strong>LangGraph</strong> to model stateful, deterministic execution flows across agents, ensuring traceability and debuggability. <br>
                        Achieved approximately <strong>70% improvement in response quality</strong> compared to the existing system and reduced <strong>end-to-end response latency by ~70%</strong>, demonstrating the effectiveness of graph-enhanced retrieval, agentic reasoning, and strict output validation for regulated healthcare environments.
                    </p>
                    <ul class="learning-outcomes">
                        <li>Validated the hypothesis that combining knowledge graphs, autonomous agents, and schema-validated LLM pipelines delivers faster, more accurate, and more explainable AI systems.</li>
                        <li>Understood trade-offs between vector-only RAG vs GraphRAG vs Agentic RAG in healthcare contexts.</li>
                        <li>Learned how to design enterprise-grade POCs with proper error handling, monitoring, and schema validation.</li>
                        <li>Gained insights into latency optimization and response quality evaluation in production AI systems.</li>
                    </ul>
                    <ul class="skills-learned">
                        <li>GraphRAG architecture design & implementation</li>
                        <li>Agentic AI workflow orchestration with LangGraph</li>
                        <li>Pydantic AI for typed, schema-validated agents</li>
                        <li>Response quality benchmarking & latency profiling</li>
                        <li>LLM output validation & hallucination reduction strategies</li>
                    </ul>
                </li>

                <!-- RAG Variants Experimentation -->
                <li class="phase">
                    <h3 class="phase-title">RAG Variants Research: Standard RAG → GraphRAG → Agentic RAG</h3>
                    <p class="phase-desc">
                        Conducted extensive experimentation with multiple Retrieval-Augmented Generation (RAG) paradigms to understand their strengths and limitations in healthcare contexts. Built <strong>standard RAG pipelines</strong> using vector databases for semantic similarity search across patient records. Implemented <strong>GraphRAG</strong>, where retrieved vector context was augmented with structured graph knowledge from patient histories and clinical ontologies. Developed <strong>Agentic RAG systems</strong> enabling autonomous agents to decide when to use vector retrieval vs graph traversal, chain multiple retrieval steps, and refine prompts based on intermediate reasoning. <br>
                        Discovered that vector-only RAG struggled with multi-hop reasoning and temporal healthcare queries, while GraphRAG significantly improved context precision and semantic grounding. Agentic RAG enabled adaptive reasoning and better handling of complex, ambiguous clinical queries.
                    </p>
                    <ul class="learning-outcomes">
                        <li>Understood when vector-only retrieval is insufficient and when graph-aware reasoning is essential.</li>
                        <li>Learned how to design hybrid retrieval strategies that balance efficiency and accuracy.</li>
                        <li>Gained experience in comparative architecture analysis across RAG paradigms.</li>
                        <li>Understood the role of autonomous agents in adaptive retrieval and multi-step reasoning.</li>
                    </ul>
                    <ul class="skills-learned">
                        <li>Vector database integration (semantic search)</li>
                        <li>GraphRAG implementation & graph-aware retrieval</li>
                        <li>Agentic workflow design & multi-step reasoning</li>
                        <li>Hybrid retrieval (vector + graph) architecture</li>
                        <li>RAG performance benchmarking & comparative analysis</li>
                    </ul>
                </li>

                <!-- Knowledge Graph Design -->
                <li class="phase">
                    <h3 class="phase-title">Patient-Centric Knowledge Graph Design & Implementation</h3>
                    <p class="phase-desc">
                        Designed and implemented individualized knowledge graphs for each patient, capturing their complete healthcare journey in a structured, queryable format. Identified and modeled core healthcare entities (patients, diagnoses, medications, procedures, lab results, encounters, timelines) and defined semantic relationships (e.g., <em>diagnosed_with</em>, <em>treated_by</em>, <em>followed_by</em>, <em>risk_factor_for</em>). Stored and managed graphs using <strong>GraphDB / Neo4j</strong> and authored optimized <strong>Cypher queries</strong> for temporal reasoning, risk factor analysis, and context extraction for RAG workflows. <br>
                        The knowledge graphs enabled explainable, graph-based reasoning over patient histories and provided rich, structured context to downstream GraphRAG and agentic pipelines, improving traceability and interpretability of AI responses in clinical and underwriting scenarios.
                    </p>
                    <ul class="learning-outcomes">
                        <li>Learned to translate clinical domain concepts into structured graph entities and relationships.</li>
                        <li>Understood temporal reasoning in graphs for healthcare timelines and event sequencing.</li>
                        <li>Gained experience designing scalable graph schemas for large patient populations.</li>
                        <li>Learned how graph structure improves explainability and interpretability of AI decisions.</li>
                    </ul>
                    <ul class="skills-learned">
                        <li>Knowledge graph design & ontology modeling</li>
                        <li>Neo4j / GraphDB graph persistence & querying</li>
                        <li>Cypher query language for temporal & multi-hop reasoning</li>
                        <li>Graph schema optimization & performance tuning</li>
                        <li>Semantic relationship modeling for healthcare domains</li>
                    </ul>
                </li>

                <!-- Healthcare Data Analysis & PUWP -->
                <li class="phase">
                    <h3 class="phase-title">Healthcare Data Analysis & Precision Underwriting (PUWP) Initiative</h3>
                    <p class="phase-desc">
                        Worked extensively on data understanding and domain modeling as part of the Precision Underwriting (PUWP) initiative. Explored and profiled large healthcare datasets to understand clinical relevance, data quality issues, and feature distributions. Identified underwriting-relevant signals from patient data and mapped raw healthcare data into structured entities suitable for graph modeling. Ensured alignment between clinical meaning and underwriting decision logic. Used <strong>Databricks & Apache Spark</strong> for large-scale data processing and profiling, and applied entity & feature extraction pipelines to transform raw records into meaningful healthcare concepts. <br>
                        This phase ensured that AI models were not only technically sound but also business-aligned and domain-aware, bridging the gap between clinical data and underwriting requirements.
                    </p>
                    <ul class="learning-outcomes">
                        <li>Learned to conduct end-to-end healthcare data analysis and identify business-relevant signals.</li>
                        <li>Understood data quality challenges specific to healthcare and mitigation strategies.</li>
                        <li>Gained experience translating business requirements into data engineering tasks.</li>
                        <li>Developed domain expertise in precision underwriting and risk assessment using clinical data.</li>
                    </ul>
                    <ul class="skills-learned">
                        <li>Healthcare data profiling & quality analysis</li>
                        <li>Databricks & Apache Spark for distributed processing</li>
                        <li>Entity & feature extraction pipelines</li>
                        <li>Clinical data modeling & domain mapping</li>
                        <li>Large-scale data processing & ETL workflows</li>
                    </ul>
                </li>

                <!-- AI Stack & Architecture Foundation -->
                <li class="phase">
                    <h3 class="phase-title">AI Stack Evaluation & Architecture Foundation</h3>
                    <p class="phase-desc">
                        Played a key role in evaluating and implementing the core AI and data infrastructure needed to support large-scale, graph-driven AI systems. Evaluated <strong>LangChain & LangGraph</strong> for structured LLM workflows, <strong>Agents & Agentic AI</strong> frameworks for autonomous reasoning, <strong>Databricks & Apache Spark</strong> for distributed data processing, and <strong>Neo4j / GraphDB</strong> for graph persistence. Integrated vector databases for dense retrieval, established <strong>Cypher</strong> querying best practices, and evaluated graph analytics tools. This architectural groundwork enabled seamless integration across data processing, graph modeling, retrieval, and LLM inference layers. <br>
                        Built reusable infrastructure and best practices that accelerated downstream development of GraphRAG and agentic AI systems, ensuring scalability, reliability, and maintainability.
                    </p>
                    <ul class="learning-outcomes">
                        <li>Understood the landscape of AI frameworks and tools for graph-driven, agentic systems.</li>
                        <li>Learned to design modular, scalable AI architecture suitable for enterprise healthcare applications.</li>
                        <li>Gained experience in evaluating trade-offs between different frameworks and infrastructure choices.</li>
                        <li>Developed expertise in end-to-end AI system design from data to inference.</li>
                    </ul>
                    <ul class="skills-learned">
                        <li>LangChain & LangGraph for structured workflows</li>
                        <li>Agentic AI framework evaluation & integration</li>
                        <li>Databricks & Apache Spark architecture</li>
                        <li>Neo4j / GraphDB infrastructure setup & optimization</li>
                        <li>Vector database integration & hybrid retrieval architecture</li>
                        <li>End-to-end AI pipeline design & orchestration</li>
                    </ul>
                </li>
            </ul>


        </div>
        <div class="card experience-card">
            <div class="experience-logo-container">
                <img src="https://raw.githubusercontent.com/RozyShindra/rozy-nit-surat/refs/heads/main/assests/images/logos/tataelectronics.png"
                    alt="TATA Electronics Logo" class="exp-logo">
                <div class="experience-text">
                    <h3>Artificial Intelligence Intern</h3>
                    <h4>TATA Electronics Private Limited</h4>
                    <p class="location">Hosur, Tamil Nadu | March 2025 – June 2025</p>
                </div>
            </div>


            <p class="summary">
                Researched and engineered AI/ML solutions for manufacturing optimization and predictive quality control.
                Worked on real-time anodization quality prediction, glue optimization, and visual defect detection —
                integrating machine learning and computer vision into industrial processes. Achieved
                <strong>~98% prediction accuracy</strong> in anodization modeling and
                <strong>>95% defect detection accuracy</strong>, reducing defects by ~30% and boosting throughput by
                ~20%.
            </p>

            <!-- Achievements Summary -->
            <h3>Achievements</h3>
            <ul class="achievements">
                <li>Designed and deployed <strong>real-time anodization prediction models</strong> achieving ~98%
                    accuracy and enabling proactive process control.</li>
                <li>Built a <strong>glue optimization pipeline</strong> using segmentation (K-means, SAM) to ensure
                    balanced glue distribution across 36–40 regions, paving the way for automated material usage
                    control.</li>
                <li>Implemented <strong>visual defect detection system</strong> with YOLO, surpassing 95% accuracy,
                    reducing defect rate by 30% and improving throughput by 20%.</li>
            </ul>
            <div class="tech-tags">
                <span class="tech-tag">Computer Vision</span>
                <span class="tech-tag">Image Segmentation</span>
                <span class="tech-tag">Object Detection</span>
                <span class="tech-tag">Industrial AI</span>
                <span class="tech-tag">Predictive Modeling</span>
                <span class="tech-tag">Machine Learning</span>
                <span class="tech-tag">Deep Learning</span>
            </div>

            <!-- Visual Defect Detection -->
            <h3>Research & Experiment</h3>
            <ul class="detailed-work">
                <li class="phase">
                    <h3 class="phase-title">Visual Defect Detection using Computer Vision</h3>
                    <p class="phase-desc">
                        Designed and implemented object detection models using YOLO for high-resolution defect
                        detection.
                        Localized component part deformation and part-level anomalies with custom anchor tuning, IoU
                        optimization,
                        and class-specific augmentation. Automated CAD-based validation of material zones and
                        dynamically flagged
                        insufficient or excess application. <br>
                        Achieved <strong>>95% detection accuracy</strong>, reducing related defects by ~30% and
                        increasing throughput by ~20%.
                    </p>
                    <ul class="learning-outcomes">
                        <li>Learned to apply deep learning object detection to manufacturing images.</li>
                        <li>Understood integration of CAD geometry with CV models for validation.</li>
                        <li>Gained insights into augmentations and anchor tuning for industrial datasets.</li>
                    </ul>
                    <ul class="skills-learned">
                        <li>YOLO (object detection)</li>
                        <li>Image augmentation & anchor tuning</li>
                        <li>IoU optimization</li>
                        <li>High-resolution industrial CV pipelines</li>
                    </ul>
                </li>

                <!-- Anodization Quality Prediction -->
                <li class="phase">
                    <h3 class="phase-title">Real-Time Anodization Quality Prediction</h3>
                    <p class="phase-desc">
                        Built predictive ML models using process + sensor data (temperature, time, concentration,
                        chemical parameters)
                        to predict anodization surface attributes — color, gloss, texture, thickness. <br>
                        Preprocessed multivariate datasets, applied dimensionality reduction, experimented with
                        classical ML algorithms,
                        ensembles, and neural networks. Introduced tolerance-based improvements to refine results. <br>
                        Reached <strong>~97–98% prediction accuracy</strong>, enabling proactive quality correction and
                        real-time control.
                    </p>
                    <ul class="learning-outcomes">
                        <li>Understood the link between sensor data and product surface properties.</li>
                        <li>Gained practice in applying ensembles + NN to multivariate industrial datasets.</li>
                        <li>Learned to design tolerance-aware metrics for business-critical predictions.</li>
                    </ul>
                    <ul class="skills-learned">
                        <li>Classical ML algorithms & ensembles</li>
                        <li>Neural networks for regression/classification</li>
                        <li>Dimensionality reduction</li>
                        <li>R², tolerance-based evaluation</li>
                    </ul>
                </li>

                <!-- Glue Optimization -->
                <li class="phase">
                    <h3 class="phase-title">Glue Optimization via Image Segmentation</h3>
                    <p class="phase-desc">
                        Developed a CV pipeline to optimize glue application. Used UV images of glued parts and applied
                        segmentation
                        (K-means clustering, statistical methods, and Segment Anything Model) to measure glue
                        distribution across
                        ~36–40 predefined zones. <br>
                        Designed a feedback mechanism for automatic control of glue amount per area based on segmented
                        distribution.
                    </p>
                    <ul class="learning-outcomes">
                        <li>Learned industrial application of image segmentation for material optimization.</li>
                        <li>Understood closed-loop feedback design to control material usage automatically.</li>
                        <li>Explored segmentation models (statistical vs modern foundation models).</li>
                    </ul>
                    <ul class="skills-learned">
                        <li>K-Means clustering</li>
                        <li>Segment Anything Model (SAM)</li>
                        <li>Statistical + deep segmentation techniques</li>
                        <li>Image-based process control</li>
                    </ul>
                </li>

                <!-- Foundations -->
                <li class="phase">
                    <h3 class="phase-title">Foundations — Shop Floor Research & Data Understanding</h3>
                    <p class="phase-desc">
                        Began by visiting the manufacturing shop floor, exploring machine mechanisms, and identifying
                        areas
                        where AI could assist workers and improve throughput. Collaborated with engineering, quality,
                        and business teams
                        to understand workflows and refine business problems. <br>
                        Collected datasets from CNC machines, sensors, and high-resolution imaging systems for
                        downstream ML/CV tasks.
                    </p>
                    <ul class="learning-outcomes">
                        <li>Learned to translate business requirements into AI opportunities.</li>
                        <li>Understood shop floor operations and machine-sensor data capture pipelines.</li>
                        <li>Developed cross-functional collaboration skills (engineering + business + quality teams).
                        </li>
                    </ul>
                    <ul class="skills-learned">
                        <li>Problem scoping & business understanding</li>
                        <li>Industrial data collection (CNC, sensors, imaging)</li>
                        <li>Domain exploration & requirement gathering</li>
                    </ul>
                </li>
            </ul>


        </div>
        <div class="card experience-card">
            <div class="experience-logo-container">
                <img src="https://raw.githubusercontent.com/RozyShindra/rozy-nit-surat/refs/heads/main/assests/images/logos/toshiba.png"
                    alt="Toshiba Logo" class="exp-logo">
                <div class="experience-text">
                    <h3>Research & Development Intern</h3>
                    <h4>Toshiba Software (India) Private Limited</h4>
                    <p class="location">Bengaluru, Karnataka | July 2024 – Jan 2025</p>
                </div>
            </div>
            <p class="summary">
                Conducted end-to-end research and engineering for Named Entity Recognition (NER),
                Keyphrase Extraction (KPE), and Text Summarization. Built and benchmarked hybrid pipelines
                combining fine-tuned extractors with LLMs, applied SFT and PEFT (LoRA, Prefix Tuning, Prompt Tuning,
                P-Tuning) techniques,
                and documented results across multiple open-source datasets — achieving <strong>~80% F1 (15–20%
                    improvement over prior baselines)</strong>
                on both nested and flat NER tasks.
            </p>
            <!-- Achievements summary -->
            <h3>Achievements</h3>
            <ul class="achievements">
                <li>Proposed Architecture: Designed and implemented a scalable NLP architecture to optimize model
                    performance and operational efficiency for information extraction. Improved information extraction
                    accuracy by 15%, achieving an 80% F1 score, making the model more reliable for domain-specific
                    tasks.</li>
                <li>Advanced NLP Solutions: Delivered state-of-the-art systems for Named Entity Recognition (NER),
                    Keyphrase Extraction (KPE), and Text Summarization, by leveraging LLMs (LLaMA, Mistral, Pegasus —
                    and 10+ LLM variants during benchmarking).</li>
                <li>Fine-Tuning Expertise: Fine-tuned Large Language Models (LLMs) using Supervised Fine-Tuning (SFT)
                    and Parameter-Efficient Fine-Tuning (PEFT) methods like LoRA, Prefix Tuning, and Prompt Tuning for
                    domain-specific applications. Benchmarked multiple LLMs on customized datasets, recorded metrics,
                    and documented all experiments for reproducibility.</li>
            </ul>
            <div class="tech-tags">
                <span class="tech-tag">Generative AI</span>
                <span class="tech-tag">Large Language Models</span>
                <span class="tech-tag">Supervised Fine-Tuning (SFT)</span>
                <span class="tech-tag">Parameter-Efficient Fine-Tuning (PEFT)</span>
                <span class="tech-tag">Quantization</span>
                <span class="tech-tag">Information Extraction</span>
                <span class="tech-tag">Text Summarization</span>
                <span class="tech-tag">Named Entity Recognition (NER)</span>
                <span class="tech-tag">Keyphrase Extraction (KPE)</span>
                <span class="tech-tag">Prompt Engineering</span>
                <span class="tech-tag">NLP Pipelines</span>
                <span class="tech-tag">NER Datasets</span>
            </div>


            <!-- Most recent -->
            <h3>Research & Experiment</h3>
            <ul class="detailed-work">
                <li class="phase">
                    <h3 class="phase-title">Text Summarization</h3>
                    <p class="phase-desc">
                        Focused on extractive and abstractive summarization using models such as BART, PEGASUS and T5.
                        Evaluated on domain-specific datasets and improved performance using Parameter-Efficient
                        Fine-Tuning
                        (PEFT) techniques — LoRA, Prefix Tuning and Prompt Tuning — to adapt pre-trained summarizers for
                        custom data.
                        Results were validated with ROUGE, BERTScore and BARTScore; extensive documentation captured
                        metric-level improvements.
                    </p>
                    <ul class="learning-outcomes">
                        <li>Learned to benchmark abstractive vs extractive summarization and identify domain-specific
                            failure modes.</li>
                        <li>Gained practical experience applying PEFT to reduce compute while improving domain
                            performance.
                        </li>
                        <li>Developed robust evaluation pipelines using ROUGE, BERTScore and BARTScore for reproducible
                            comparison.</li>
                    </ul>
                    <div class="tech-tags">
                        <span class="tech-tag">PEFT (LoRA, Prefix Tuning, Prompt Tuning)</span>
                        <span class="tech-tag">BART, PEGASUS, T5</span>
                        <span class="tech-tag">Model evaluation</span>
                        <span class="tech-tag">ROUGE</span>
                        <span class="tech-tag">BERTScore</span>
                        <span class="tech-tag">BARTScore</span>
                        <span class="tech-tag">Precision/Recall/F1</span>
                        <span class="tech-tag">Experiment logging</span>
                        <span class="tech-tag">Reproducible Reporting</span>
                    </div>

                </li>



                <!-- Hybrid approach -->
                <li class="phase">
                    <h3 class="phase-title">Hybrid NER Approach — Key Research Contribution</h3>
                    <p class="phase-desc">
                        Designed and implemented a two-stage hybrid pipeline:
                        <span class="step">(1) A fine-tuned Keyphrase Extractor to surface domain-relevant candidate
                            phrases</span>
                        <span class="step">(2) A few-shot fine-tuned LLM (LLaMA / Qwen / Mistral) to perform
                            context-aware entity extraction</span>
                    </p>
                    This combination achieved ~80% F1 on nested and flat NER tasks — a 15–20% improvement compared to
                    baseline pipelines.
                    Comprehensive experiment logs documented datasets, prompts, model checkpoints and evaluation
                    metrics.
                    </p>
                    <ul class="learning-outcomes">
                        <li>Validated the hypothesis that targeted KPE + LLM reasoning outperforms standalone approaches
                            in
                            domain settings.</li>
                        <li>Learned how to design pipelines that balance lightweight extractors with heavy LLM reasoning
                            for
                            efficiency and accuracy.</li>
                        <li>Gained experience in error analysis on nested vs flat entities and iterating on extractor +
                            prompt design.</li>
                    </ul>
                    <ul class="skills-learned">
                        <li>Hybrid pipeline design (KPE → LLM)</li>
                        <li>Few-shot prompting and prompt template design</li>
                        <li>Model orchestration & result reproducibility</li>
                        <li>Performance analysis for nested vs flat entity recognition</li>
                    </ul>
                </li>

                <!-- LLM experiments -->
                <li class="phase">
                    <h3 class="phase-title">LLM Experiments for NER</h3>
                    <p class="phase-desc">
                        Performed systematic prompt engineering experiments (zero-shot, few-shot, chain-of-thought,
                        tree-of-thought)
                        across open-source LLMs and many NER datasets (ACE2004/2005, GENIA, CoNLL2003, MultiNERD,
                        OntoNotes,
                        TweetNER7, CrossNER, MIT datasets).
                        Followed up with Supervised Fine-Tuning (SFT) and combined SFT + prompt engineering to improve
                        precision and recall.
                    </p>
                    <ul class="learning-outcomes">
                        <li>Understood when prompts are sufficient and when fine-tuning is required (low-resource vs
                            high-resource trade-offs).</li>
                        <li>Learned advanced prompting patterns (CoT/ToT) and their practical limits for structured IE
                            tasks.</li>
                        <li>Captured model behavior across domains and adapted prompts/schema to reduce hallucination
                            and
                            improve consistency.</li>
                    </ul>
                    <ul class="skills-learned">
                        <li>Prompt engineering: zero-shot, few-shot, chain-of-thought, tree-of-thought</li>
                        <li>LLM fine-tuning (SFT) and combining SFT with prompts</li>
                        <li>Open-source LLMs: LLaMA, Qwen, Mistral (experimentation & benchmarking)</li>
                        <li>Artifact/version management for model checkpoints</li>
                    </ul>
                </li>

                <!-- Keyphrase extraction -->
                <li class="phase">
                    <h3 class="phase-title">Keyphrase Extraction Research</h3>
                    <p class="phase-desc">
                        Carried out an in-depth benchmarking of keyphrase extraction methods — statistical (YAKE, RAKE),
                        embedding-based (KeyBERT),
                        position/graph-based (PositionRank) and transformer-based KPE variants. Compared domain
                        generality
                        and semantic recall,
                        and used this analysis to drive the design of the hybrid pipeline.
                    </p>
                    <ul class="learning-outcomes">
                        <li>Identified strengths/weaknesses of lightweight statistical methods vs contextual/transformer
                            methods.</li>
                        <li>Learned how KPE errors propagate to downstream NER and how to mitigate via
                            prompt/fine-tuning
                            strategies.</li>
                        <li>Designed evaluation criteria balancing precision of extracted keyphrases and downstream
                            entity
                            recall.</li>
                    </ul>
                    <ul class="skills-learned">
                        <li>Keyphrase extraction: YAKE, RAKE, KeyBERT, PositionRank</li>
                        <li>Embedding-based semantic matching and cluster-based selection</li>
                        <li>Downstream evaluation design (KPE → NER impact measurement)</li>
                    </ul>
                </li>

                <!-- Non-LLM experiments -->
                <li class="phase">
                    <h3 class="phase-title">Non-LLM NER Experiments</h3>
                    <p class="phase-desc">
                        Implemented and benchmarked non-LLM architectures including Binder and DiffusionNER across
                        nested
                        and flat NER datasets.
                        Binder consistently outperformed DiffusionNER on nested datasets (e.g., GENIA: Binder ~79.8 F1
                        vs
                        DiffusionNER ~69.6),
                        establishing strong baselines for comparison with LLM approaches.
                    </p>
                    <ul class="learning-outcomes">
                        <li>Learned practical trade-offs: non-LLM efficiency vs LLM generalization in low-resource
                            scenarios.</li>
                        <li>Built baseline reproducibility pipelines and used them as a comparison target for later
                            hybrid
                            approaches.</li>
                        <li>Understood dataset-specific behaviors (why Binder excels on nested entities and where it
                            fails).
                        </li>
                    </ul>
                    <ul class="skills-learned">
                        <li>Non-LLM models: Binder, DiffusionNER</li>
                        <li>Dataset handling for ACE, GENIA, CoNLL, OntoNotes, MultiNERD</li>
                        <li>Baseline experiment design and metric-driven comparisons</li>
                    </ul>
                </li>

                <!-- Foundations -->
                <li class="phase">
                    <h3 class="phase-title">Research Foundations (Initial Work)</h3>
                    <p class="phase-desc">
                        Kicked off with a thorough literature survey covering modern NER and UIE research (GLiNER,
                        InstructUIE, GoLLIE, UniversalNER,
                        KnowCoder, DiffusionNER). Studied prompt paradigms, annotation guideline effects and established
                        experiment/annotation standards.
                        Created the initial documentation and experiment templates used throughout the project.
                    </p>
                    <ul class="learning-outcomes">
                        <li>Built a strong theoretical foundation in NER/UIE research and annotation practices.</li>
                        <li>Learned how to design reproducible experiments and consistent documentation standards.</li>
                        <li>Established clear baselines, dataset splits, and annotation guidelines for downstream work.
                        </li>
                    </ul>
                    <ul class="skills-learned">
                        <li>Literature review and critical analysis of NER/UIE papers</li>
                        <li>Experiment planning, annotation guideline design</li>
                        <li>Technical writing and reproducible documentation</li>
                    </ul>
                </li>
            </ul>

        </div>

        <div class="card experience-card">
            <div class="experience-logo-container">
                <img src="https://raw.githubusercontent.com/RozyShindra/rozy-nit-surat/refs/heads/main/assests/images/logos/svnit.png"
                    alt="Toshiba Logo" class="exp-logo">
                <div class="experience-text">
                    <h3>Teaching Assistant</h3>
                    <h4>Sardar Vallabhbhai National Institute of Technology</h4>
                    <p class="location">Surat, Gujarat | Aug 2023 – July 2024</p>
                </div>
            </div>
            <ul class="achievements">
                <li>Assisted in teaching and mentoring undergraduate students in Computer Science Fundamentals,
                    Data Structures, Algorithms, C, and C++, focusing on concepts such as time/space complexity
                    analysis,
                    recursion, dynamic memory management, and object-oriented programming.</li>
                <li>Conducted laboratory sessions, coding tutorials, and algorithm walkthroughs,
                    enabling students to implement core data structures (arrays, linked lists, stacks, queues, trees,
                    graphs)
                    and apply sorting, searching, and hashing techniques in C/C++.</li>
                <li>Supported faculty in preparing course modules, designing algorithm-based assignments,
                    and evaluating lab work and examinations, ensuring alignment with ACM/IEEE computer science
                    curriculum standards.</li>
                <li>Guided students in problem decomposition, algorithmic optimization,
                    and structured programming practices, encouraging them to adopt modular design, debugging
                    techniques,
                    and efficiency-driven coding methodologies.</li>
            </ul>
            <div class="tech-tags">
                <span class="tech-tag">Computer Science Fundamentals</span>
                <span class="tech-tag">Data Structures</span>
                <span class="tech-tag">Algorithms</span>
                <span class="tech-tag">C Language</span>
                <span class="tech-tag">C++</span>
                <span class="tech-tag">Dynamic Programming</span>
                <span class="tech-tag">Coding</span>
                <span class="tech-tag">Object Orienteted Programming</span>
                <span class="tech-tag">Time & Space Complexity</span>
                <span class="tech-tag">Recursion</span>
                <span class="tech-tag">Problem Decomposition</span>
            </div>
        </div>
    </div>
</div>